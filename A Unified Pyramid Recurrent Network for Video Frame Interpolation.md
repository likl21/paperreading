## A Unified Pyramid Recurrent Network for Video Frame Interpolation

### 一、

##### UPR的特别之处

继承了金字塔循环双向流估计的优点，允许定制化层数，拓展：从粗到细的帧合成

向帧合成模块提供从先前较低分辨率的金字塔级别上采样的中间帧估计，可以在large motion cases下明显改善插帧的鲁棒性

光流和合成帧组件都是轻量的

> 在金字塔每一层，首先提取输入帧的CNN特征，然后构建一个correlation volume用于同步的双向流估计
>
> 根据前向扭曲（forward-warped）的输入帧及其CNN特征，以及上采样的中间帧来预测精细的中间帧



### 二、相关工作

##### 金字塔循环光流估计器

传统的PWC-Net，金字塔层数固定，难以处理large motions

金字塔循环光流估计器处理large motion，在不同层之间共享结构，并且定制层数

先前的金字塔每层使用一个简单的U-Net作为base 估计器，U-Net由于缺少correlation volume 显得过于简单

最近，EBME将correlation volume合并到金字塔循环网络中，以进行同步双向流估计

##### 从粗到细的图片合成

首先合成低分辨率的图像，之后迭代细化，直到生成高分辨率的输出

UPR在金字塔循环架构中迭代强化中间帧

##### 扭曲帧的artifacts

扭曲可以补偿每个像素的运动，但通常会产生失真和伪影

> 如果一个像素被移动到新的位置，没有其他像素移动到旧位置，则在后向扭曲的帧中该像素会出现两次，或者在前向扭曲的帧的原位置中留下一个洞

现存的插帧方法给合成网络提供扭曲的帧以及上下文特征

此外，在前向扭曲时，映射到同一目标的冲突像素应该通过简单平均或者加权平均解决，UPR使用了平均泼溅（average splatting）



### 三、Our Approach

#### 1.统一的金字塔循环网络

![image-20240716150100132](C:\Users\DELL\Desktop\markdown图片\image-20240716150100132.png)

在一个金字塔流程中统一了双向流估计和帧合成，并在在不同层之间共享参数

给定两个连续帧$I_0,I_1$，UPR在L个图像金字塔层上迭代强化，从顶层（下采样的帧$I_0^{L-1},I_1^{L-1}$）到底层（原始输入帧$I_0^0,I_1^1$）

在每一层中，使用一个特征编码器对每个输入帧提取多尺度的CNN特征，然后上一层金字塔的特征编码器产生的特征和从上层上采样的光流被一个双向流组件处理，产生一个更精细的双向光流。这个更精细的光流被用于前向扭曲输入帧和多尺度的CNN特征

结合warped representations 和 interpolation upsampled from previous level，采用帧合成组件来生成更精细的中间帧

估计过程一直重复，直到在底层产生最终的插入帧

#### 2.循环插帧组件

##### 特征编码器

对于光流，常见做法是逐像素提取特征，并用特征构建correlation volume

对于插帧，常见做法是给合成网络提供扭曲的特征来产生上下文线索

在金字塔每一层，首先使用特征编码器来给输入帧提取多尺度的特征

特征编码器有三个卷积阶段stage-0,1,2，每个节点包括4个卷积层，1和2的第一层进行下采样。我们使用每一个阶段最后一个卷积层的特征

对于第l层金字塔的图片$I_0^l,I_1^l$，将3个阶段的特征分别表示为$\left\{C_0^{l,0},C_1^{l,0}\right\},\left\{C_0^{l,1},C_1^{l,1}\right\},\left\{C_0^{l,2},C_1^{l,2}\right\}$，最后一组特征被用于双向流估计，所有的特征都被用于上下文感知的帧合成

##### 双向流组件

类似EBME，迭代合成，使用和合成模块共享的特征编码器的特征，前向扭曲CNN特征而不是输入帧

![image-20240716163924443](C:\Users\DELL\Desktop\markdown图片\image-20240716163924443.png)

$F_{0\rightarrow1}^{l+1}$和$F_{1\rightarrow0}^{l+1}$代表第$l+1$层细化的双向光流

在$l$层，首先初始化双向光流通过×2上采样$F_{0\rightarrow1}^{l+1}$和$F_{1\rightarrow0}^{l+1}$

![image-20240716162546669](C:\Users\DELL\Desktop\markdown图片\image-20240716162546669.png)

其中，在顶层被初始化为0。基于初始化的流，可以通过线性缩放获得从输入帧$I_0^l$和$I_1^l$到隐藏的中间帧$I_{0.5}^l$的光流

![image-20240716162900853](C:\Users\DELL\Desktop\markdown图片\image-20240716162900853.png)

有了$\hat{F}_{0\rightarrow0.5}^l$和$\hat{F}_{1\rightarrow0.5}^l$，可以前向扭曲CNN特征$\left\{C_0^{l,2},C_1^{l,2}\right\}$到中间帧来对齐它们的像素

然后使用扭曲的特征构建一个部分correlation volume，并且使用一个6层的CNN预测细化的双向流$F_{0\rightarrow1}^{l}$和$F_{1\rightarrow0}^{l}$，输入CNN预测器的是correlation volume、扭曲特征、初始光流$\hat{F}_{0\rightarrow1}^l$、$\hat{F}_{1\rightarrow0}^l$的串联，以及上一层金字塔CNN预测器第5层上采样的特征

因为扭曲特征的分辨率是输入帧的1/4，预测的光流也是1/4，使用双线性插值将光流上采样到原始规模

##### 帧合成组件

区别于其他上下文感知合成网络的两个特点：首先给网络提供中间帧的上采样估计，其次合成模块在不同金字塔层之间共享

![image-20240716170913607](C:\Users\DELL\Desktop\markdown图片\image-20240716170913607.png)

基于U-Net，编码器部分（不同于特征编码器）有三个卷积阶段，每个卷积阶段由三个卷积层组成，2、3阶段的第一层执行下采样。解码器部分也有三个卷积阶段，有两个转置卷积层用于上采样

在第$l$层金字塔，给定细化的双向流$F_{0\rightarrow1}^{l}$和$F_{1\rightarrow0}^{l}$，可以通过线性缩放获得从输入帧到目标帧的光流

![image-20240716165817719](C:\Users\DELL\Desktop\markdown图片\image-20240716165817719.png)

有了二者，可以前向扭曲输入帧以及它们的多尺度上下文特征$\left\{C_0^{l,0},C_1^{l,0}\right\},\left\{C_0^{l,1},C_1^{l,1}\right\},\left\{C_0^{l,2},C_1^{l,2}\right\}$

此外，还通过上采样上一层金字塔层$l+1$的插帧，生成一个中间帧的初始估计$\hat{I}_t^l$。在顶层，初始估计被设置为两个扭曲帧的平均

![](C:\Users\DELL\Desktop\markdown图片\image-20240716170124320.png)

基于此，我们给合成组件的第一个编码阶段提供扭曲的帧、对于中间帧的初始化估计$\hat{I}_t^l$、原先的输入帧以及缩放的双向流$F_{0\rightarrow t}^{l}$和$F_{1\rightarrow t}^{l}$

给编码器二、三阶段以及解码器的第一阶段提供扭曲的上下文特征

帧合成组件的输出包括两个映射$M_0^l$和$M_1^l$，用于融合两个前向扭曲的帧$I_{0\rightarrow t}^{l}$和$I_{1\rightarrow t}^{l}$，还包括一个残留图象$\Delta I_t^l$，用于进一步的细化。之后获得细化的中间帧

![image-20240716170823547](C:\Users\DELL\Desktop\markdown图片\image-20240716170823547.png)

##### 对于large motion的迭代合成的分析

从粗到细迭代合成有助于高分辨率的帧合成，同时能够干山large motion下的插帧的鲁棒性

简单的合成策略：不给合成模块提供中间帧的上采样估计，实际的合成只在最底层执行，因为先前层的合成无法影响底层的帧合成

在large motion上综合比较简单合成和迭代合成：

* 使用简单合成时，large motion下的前向扭曲帧可能导致插入帧出现明显的伪影
* 粗到细的迭代合成可实现鲁棒插帧，即使扭曲帧有明显伪影。我们假设在低分辨率金字塔层合成的上采样的插帧，由于较小的运动幅度，伪影不明显
* 上述假设在图6中被证实，在降低分辨率的情况下插入相同实例，1/8分辨率下，由于运动幅度较小，简单合成也几乎没有伪影。而迭代合成使用了低分辨率的插帧，表现一直很好

#### 3.测试中的分辨率感知适应

##### 定制化金字塔层数

假设训练中的金字塔层数为$L^{train}$，测试图像的宽度是训练图像的n倍，测试时的金字塔层数如下：

![image-20240717101838004](C:\Users\DELL\Desktop\markdown图片\image-20240717101838004.png)

##### 对于4K输入跳过高分辨率层级、

默认情况下，在$l$层上采样$l+1$层的光流和插入帧作为初始化，但是可以如果有必要可以从任意层上采样。在4K数据集上跳过最后两高分辨率层进行流量估计和倒数第二层进行帧合成，可以提高准确性

#### 4.架构变体

缩放特征通道，构建了三个变体

UPR-Net：base版本，特征编码器三个阶段的通道数为16、32、64。光流组件中6层CNN的通道数分别为160、128、112、96、64。合成组件的三个编码阶段通道数分别为32、64、128

UPR-Net：large版本，通道数×1.5

UPR-Net：LARGE版本，通道数×2.0



### 四、实现细节

##### 损失函数

Charbonnier损失和census损失的和，在ground truth $I_t^{GT}$和最底层的插帧估计$I_t$之间

![image-20240717102923403](C:\Users\DELL\Desktop\markdown图片\image-20240717102923403.png)

##### 训练数据集

Vimeo90K：51312个分辨率448×256的三元组，并且通过随机裁剪256×256的块来增强图像，同时还有随机翻转、旋转、乱序来增强

##### 训练中的金字塔层数

UPR-Net版本的金字塔层数为3层

##### 优化

AdamW优化器，权重衰减为$10^{-4}$，800000次迭代，batch size为32

余弦退火训练，学习率从$2×10^{-4}$逐渐降为$2×10^{-5}$



### 五、实验

![image-20240717103951042](C:\Users\DELL\Desktop\markdown图片\image-20240717103951042.png)

![image-20240717104946912](C:\Users\DELL\Desktop\markdown图片\image-20240717104946912.png)

##### 评价数据集

UCF101、Vimeo90K、SNU-FILM、4K1000FPS

##### 分辨率感知适应

根据金字塔层数公式，上述1、3、4数据集的金字塔层数分别为3、5、7

在4K1000FPS数据集上，跳过了最后两层和倒数第二层

##### 评价指标

PSNR、SSIM

##### 设计选择的消融研究、

![image-20240717104924275](C:\Users\DELL\Desktop\markdown图片\image-20240717104924275.png)

用三层级联模块替代循环模块，在低分辨率上效果较好，但是由于测试时不能定制化金字塔层数，处理large motion时缺少灵活性，中和高分辨率上效果不好

不上采样的简单合成模块在V90K上效果好，可能表面在低分辨率图像上迭代合成是不必须的

构建了一个流水线用于双向流和帧合成，包括两个分开的金字塔神经网络（特征编码器也是分开的）

从光流组件中移除了correlation volume，效果下降

移除上下文特征，在V90K上明显下降



### 六、未来工作

用现有的光流模型替换运动估计器；研究训练期间的多帧插入是否有利于测试中的多帧插入